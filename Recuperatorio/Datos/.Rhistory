data_fb$x3 <- suppressWarnings(as.numeric(data_fb$x3))
data_fb$x4 <- suppressWarnings(as.numeric(data_fb$x4))
data_fb$x5 <- suppressWarnings(as.numeric(data_fb$x5))
data_fb$x6 <- suppressWarnings(as.numeric(data_fb$x6))
data_fb$x7 <- suppressWarnings(as.numeric(data_fb$x7))
data_fb$x8 <- suppressWarnings(as.numeric(data_fb$x8))
data_fb$y <- suppressWarnings(as.numeric(data_fb$x1))
attach(data_fb)
summary(data_fb)
#ELIMINAMOS LA OBSERVACION -17 PORQUE LA MISMA NO TIENE SENTIDO EN EL CONTEXTO QUE MANEJAMOS
#CLARAMENTE SE TRATA DE UN VALOR ANOMALO
data_fb <- data_fb[x3 != -17,]
nrow(data_fb)
view(data_fb)
summary(data_fb)
data_fb <- data_fb[!(data_fb$x2 %in% c(497910,457509,453213)),] #ELIMINAR OUTLIERS ESPECIFICOS
data_fb <- data_fb[!(data_fb$x6 %in% c(160270,184270)),]
set.seed(63)
data_fb_particion <- createDataPartition(data_fb$y, p=0.7, list=FALSE)
datafb_train<-data_fb[data_fb_particion,]
dataTrain_corr <- cor(datafb_train) #UNICAMENTE CON VARIABLES NUMERICAS
dataTrain_corr
corrplot(dataTrain_corr, method="number",tl.col="black",tl.cex=0.5)
datatrain_rlm <- lm(y ~ ., data = datafb_train)
rm(list=ls()) # Eliminacion de variables del entorno
options(scipen = 6) # Para evitar notacion cientifica.
# CARGA DE DATOS
datos <- read_delim("Datos/data.fb.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)
library(readr)
data_fb <- read_delim("C:/Users/Facundo/Desktop/UNO/Explotacion de Datos/Parcial - Recuperatorio/DATOS/data.fb.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
View(data_fb)
# BUSQUEDA DE DATOS NULOS
# Visualizamos un resumen de datos nulos en el conjunto de datos.
# View(summarise_all(datos, funs(sum(is.na(.)))))
datos <- na.omit(datos) # Eliminamos las filas con valores nulos en caso de haber
datos<-data_fb
# BUSQUEDA DE DATOS NULOS
# Visualizamos un resumen de datos nulos en el conjunto de datos.
# View(summarise_all(datos, funs(sum(is.na(.)))))
datos <- na.omit(datos) # Eliminamos las filas con valores nulos en caso de haber
# VEMOS LOS DATOS
View(datos)
# CASTEO DE DATOS
# Convertimos todas las columnas a tipo numerico para asegurarnos de que sean interpretables.
attach(datos)
datos <- datos %>% mutate_all(as.numeric)
# ANALISIS EXPLORATORIO DE DATOS
summary(datos)  # Estadasticas descriptivas
# Boxplot
boxplot(x1,
main = "Boxplot de Datos",
xlab = "Variable X",
ylab = "Variable Y",
col = "lightblue",
border = "blue",
horizontal = TRUE)
boxplot(x4,
main = "Boxplot de Datos",
xlab = "Variable X",
ylab = "Variable Y",
col = "lightblue",
border = "blue",
horizontal = TRUE)
boxplot(y,
main = "Boxplot de Datos",
xlab = "Variable X",
ylab = "Variable Y",
col = "lightblue",
border = "blue",
horizontal = TRUE)
boxplot(datos,
main = "Boxplot de Datos",
xlab = "Variable X",
ylab = "Variable Y",
col = "lightblue",
border = "blue",
horizontal = TRUE)
boxplot(datos,
main = "Boxplot de Datos",
xlab = "Variable X",
ylab = "Variable Y",
col = "lightblue",
border = "blue",
horizontal = TRUE)
################################################################################################
# REGRESION PARA PREDECIR Y
set.seed(16)
parte <- createDataPartition(datos$y, p=0.7, list=FALSE)
train<-datos[parte,]
test<-datos[-parte,]
# Vemos la correlacion entre valores
corrplot(cor(datos), method = "number", tl.col = "black", tl.cex = 0.8)
##  RLM para predecir "Y"
mod_full<-lm(y~.,data=train)
summary(mod_full)
# modStep_for <- step(mod_full, direction = "forward",trace=T)
modStep_back <- step(mod_full, direction = "backward",trace=T)
# modStep_both <- step(mod_full, direction = "both",trace=F)
# summary(modStep_for)
summary(modStep_back)
# summary(modStep_both)
# Nos da formula con todas las variables, quiere decir que todas son necesarias para nuestra
# predicci?n
y_pred2 <- predict(object=modStep_back, newdata=test)
plot(test$y,y_pred2,pch=20,main="predichos backward",  xlab='Y', ylab=expression(hat(y)))
abline(a=0, b=1, col="green")
# Elegir modelo
modelo <- modStep_back
residuos = residuals(modelo)
summary(residuos)
hist(residuos) # Vemos si se da la campana de Gauss
################################################################################
######################## VERIFICAR SUPUESTOS DE LA RLM #########################
par(mfrow=c(2,2))
plot(modelo)
# 1. Linealidad: Dispersion sin patron alguno de residuos, viendo plots del modelo y residuos
plot(residuos)
# 2. homocedasticidad: verificar la homocedasticidad graficando los residuos estandarizados
# Grafico de Scale-Location
# Boxplot debe tener mediana 0 (de residuos)
boxplot(residuos,
main = "Boxplot de Datos",
xlab = "Variable X",
ylab = "Variable Y",
col = "lightblue",
border = "blue",
horizontal = TRUE)
# 1. Linealidad: Dispersion sin patron alguno de residuos, viendo plots del modelo y residuos
plot(residuos)
# 2. homocedasticidad: verificar la homocedasticidad graficando los residuos estandarizados
# Grafico de Scale-Location
# Boxplot debe tener mediana 0 (de residuos)
boxplot(residuos,
main = "Boxplot de Datos",
xlab = "Variable X",
ylab = "Variable Y",
col = "lightblue",
border = "blue",
horizontal = TRUE)
# 4. Independencia de los residuos: usar test de Durbin Watson
# Errores independientes (no correlacionados, es equivalente si hay normalidad)
# Test Durbin Watson
# DW debe ser cercano a 2 y el p-value cercano a 1 para demostrarlo
# un pvalue muy pequenio indica que no hay independencia (están correlacionados)
# La hipotesis nula es que no hay autocorrelacion.
dwtest(modelo)  # Si el pvalor es chico, entonces hay dependencias entre residuos
data_fb <- read_delim("C:/Users/Facundo/Desktop/UNO/Explotacion de Datos/Parcial - Recuperatorio/DATOS/data.fb.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
str(data_fb)
sapply(data_fb, function(x) sum(is.na(x)))
data_fb<-na.omit(data_fb)
#CASTEAMOS LOS DATOS POR LAS DUDAS
data_fb$x1 <- suppressWarnings(as.numeric(data_fb$x1))
data_fb$x2 <- suppressWarnings(as.numeric(data_fb$x2))
data_fb$x3 <- suppressWarnings(as.numeric(data_fb$x3))
data_fb$x4 <- suppressWarnings(as.numeric(data_fb$x4))
data_fb$x5 <- suppressWarnings(as.numeric(data_fb$x5))
data_fb$x6 <- suppressWarnings(as.numeric(data_fb$x6))
data_fb$x7 <- suppressWarnings(as.numeric(data_fb$x7))
data_fb$x8 <- suppressWarnings(as.numeric(data_fb$x8))
data_fb$y <- suppressWarnings(as.numeric(data_fb$x1))
attach(data_fb)
summary(data_fb)
#ELIMINAMOS LA OBSERVACION -17 PORQUE LA MISMA NO TIENE SENTIDO EN EL CONTEXTO QUE MANEJAMOS
#CLARAMENTE SE TRATA DE UN VALOR ANOMALO
data_fb <- data_fb[x3 != -17,]
nrow(data_fb)
view(data_fb)
summary(data_fb)
data_fb_box <- plot_ly(y=data_fb$x1, type="box", name="Lifetime Post Total Reach") %>%
add_trace(y=data_fb$x2, type="box", name="Lifetime Post Total Impressions") %>%
add_trace(y=data_fb$x3, type="box", name="Lifetime Engaged Users") %>%
add_trace(y=data_fb$x4, type="box", name="Lifetime Post Consumers") %>%
add_trace(y=data_fb$x5, type="box", name="Lifetime Post Consumptions") %>%
add_trace(y=data_fb$x6, type="box", name="Lifetime Post Impressions by people who have liked your Page") %>%
add_trace(y=data_fb$x7, type="box", name="Lifetime Post reach by people who like your Page")%>%
add_trace(y=data_fb$x8, type="box", name="Lifetime People who have liked your Page and engaged with your post")%>%
add_trace(y=data_fb$y, type="box", name="Total Interactions")
data_fb_box
datafb_out <- boxplot(data_fb$x6, col="skyblue", frame.plot=F)
datafb_out$out
data_fb <- data_fb[!(data_fb$x2 %in% c(497910,457509,453213)),] #ELIMINAR OUTLIERS ESPECIFICOS
data_fb <- data_fb[!(data_fb$x6 %in% c(160270,184270)),]
set.seed(63)
data_fb_particion <- createDataPartition(data_fb$y, p=0.7, list=FALSE)
datafb_train<-data_fb[data_fb_particion,]
datafb_test<-data_fb[-data_fb_particion,]
dataTrain_corr <- cor(datafb_train) #UNICAMENTE CON VARIABLES NUMERICAS
dataTrain_corr
corrplot(dataTrain_corr, method="number",tl.col="black",tl.cex=0.5)
datatrain_rlm <- lm(y ~ ., data = datafb_train)
View(datatrain_rlm)
ggplot(datatrain_rlm, aes(x= x1 + x2 +x3 + x4 + x5 + x6 + x7 + x8, y=y))+
geom_point() +
geom_smooth(method='lm',se=FALSE, col='green') +
theme_light()
summary(datatrain_rlm)
summary(datatrain_rlm)
datatrain_rlm <- lm(y ~ ., data = datafb_train)
View(datatrain_rlm)
par(mfrow=c(2,2)) # VER LOS 4 GRAFICOS JUNTOS
plot(datatrain_rlm)
datatrain_rlm_residuos = residuals(datatrain_rlm)
boxplot(datatrain_rlm_residuos, col = "blue",horizontal=TRUE,ylim = c(-2,2),main="Box-plot de residuos")
plot_datasetTrain_residuos <- plot_ly(y = ~datatrain_rlm_residuos, type = "box")
plot_datasetTrain_residuos
datafb_res_out <- boxplot(datatrain_rlm_residuos, col="skyblue", frame.plot=F)
datatrain_backward = residuals(datatrain_backward)
datafb_res_out <- boxplot(datatrain_rlm_residuos, col="skyblue", frame.plot=F)
#Test de normalidad de Shapiro-Wilk (muestras chicas)
#Cuanto más cercano esté W a 1, más probable es que los datos se ajusten a una distribución normal.
#Si el p-valor es mayor que el nivel de significancia (ejemplo 0.05), se asume que los datos siguen una
#distribución normal.
modeltest <- datatrain_rlm
modeltest.test <- shapiro.test(modeltest )
modeltest.test <- shapiro.test(modeltest)
datatrain_rlm_residuos.test <- shapiro.test(datatrain_rlm_residuos)
print(datatrain_rlm.test)
print(datatrain_rlm_residuos.test)
dwtest(modeltest)
vif(datatrain_rlm)
ble)
##########################################################################################
#################################### BIBLIOTECAS #########################################
##########################################################################################
library(xtable)
library(corrplot)
library(readr)
library(dplyr)
library(sqldf)
library(stringi)
library(plotly)
library(tidyverse)
library(TTR)
library(fpp3)
library(scales)
library(xts)
library(plotly)
library(nortest)
library(lmtest)
library (car)
library(fmsb)
library(broom)
library(readr)
library(dplyr)
library(psych)
library(tidyverse)
library(sqldf)
library(xtable)
library(factoextra)
library(readr)
library(dplyr)
library(psych)
library(tidyverse)
library(sqldf)
library(xtable)
library(factoextra)
library(philentropy)
install.packages("ROCR")
library(TTR)
library(tsibble)
library(readr)
library(sqldf)
library(tidyverse)
library(stringi)
library(stringr)
library(ROCR)
library(plyr)
library(caret)
library(gridExtra)
library(dplyr)
library(tidyr)
library(corrplot)
library(ggplot2)
library(rpart)
library(pROC)
library(MASS)
library(e1071)
library(ggpubr)
library(rsample)
library(e1071)
library(GGally)
library(data.table)
library(DT)
library(ROCR)
library(gplots)
library(randomForest)
library(rpart.plot)
library(stringi)
library(plyr)
library(rpart)
library(rpart.plot)
library(caret)
library(ggplot2)
library(gridExtra)
library(tidyverse)
library(rsample)
library(e1071)
library(GGally)
library(data.table)
library(DT)
library(readr)
library(dplyr)
library(tidyr)
library(corrplot)
#library(rms)
library(MASS)
library(e1071)
library(ROCR)
library(gplots)
library(pROC)
library(randomForest)
library(ggpubr)
library(plotly)
library(dplyr)
data_fb <- read_delim("C:/Users/Facundo/Desktop/UNO/Explotacion de Datos/Parcial - Recuperatorio/DATOS/data.fb.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
str(data_fb)
sapply(data_fb, function(x) sum(is.na(x)))
data_fb<-na.omit(data_fb)
#CASTEAMOS LOS DATOS POR LAS DUDAS
data_fb$x1 <- suppressWarnings(as.numeric(data_fb$x1))
data_fb$x2 <- suppressWarnings(as.numeric(data_fb$x2))
data_fb$x3 <- suppressWarnings(as.numeric(data_fb$x3))
data_fb$x4 <- suppressWarnings(as.numeric(data_fb$x4))
data_fb$x5 <- suppressWarnings(as.numeric(data_fb$x5))
data_fb$x6 <- suppressWarnings(as.numeric(data_fb$x6))
data_fb$x7 <- suppressWarnings(as.numeric(data_fb$x7))
data_fb$x8 <- suppressWarnings(as.numeric(data_fb$x8))
data_fb$y <- suppressWarnings(as.numeric(data_fb$x1))
data_fb$y <- suppressWarnings(as.numeric(data_fb$y))
attach(data_fb)
summary(data_fb)
#ELIMINAMOS LA OBSERVACION -17 PORQUE LA MISMA NO TIENE SENTIDO EN EL CONTEXTO QUE MANEJAMOS
#CLARAMENTE SE TRATA DE UN VALOR ANOMALO
data_fb <- data_fb[x3 != -17,]
nrow(data_fb)
view(data_fb)
nrow(data_fb)
summary(data_fb)
data_fb_box <- plot_ly(y=data_fb$x1, type="box", name="Lifetime Post Total Reach") %>%
add_trace(y=data_fb$x2, type="box", name="Lifetime Post Total Impressions") %>%
add_trace(y=data_fb$x3, type="box", name="Lifetime Engaged Users") %>%
add_trace(y=data_fb$x4, type="box", name="Lifetime Post Consumers") %>%
add_trace(y=data_fb$x5, type="box", name="Lifetime Post Consumptions") %>%
add_trace(y=data_fb$x6, type="box", name="Lifetime Post Impressions by people who have liked your Page") %>%
add_trace(y=data_fb$x7, type="box", name="Lifetime Post reach by people who like your Page")%>%
add_trace(y=data_fb$x8, type="box", name="Lifetime People who have liked your Page and engaged with your post")%>%
add_trace(y=data_fb$y, type="box", name="Total Interactions")
data_fb_box
data_fb <- data_fb[!(data_fb$x2 %in% c(497910,457509,453213)),] #ELIMINAR OUTLIERS ESPECIFICOS
data_fb <- data_fb[!(data_fb$x6 %in% c(160270,184270)),]
set.seed(63)
data_fb_particion <- createDataPartition(data_fb$y, p=0.7, list=FALSE)
datafb_train<-data_fb[data_fb_particion,]
datafb_test<-data_fb[-data_fb_particion,]
dataTrain_corr <- cor(datafb_train) #UNICAMENTE CON VARIABLES NUMERICAS
dataTrain_corr
corrplot(dataTrain_corr, method="number",tl.col="black",tl.cex=0.5)
datatrain_rlm <- lm(y ~ ., data = datafb_train)
summary(datatrain_rlm)
ggplot(datatrain_rlm, aes(x= x1 + x2 +x3 + x4 + x5 + x6 + x7 + x8, y=y))+
geom_point() +
geom_smooth(method='lm',se=FALSE, col='green') +
theme_light()
datatrain_backward <- step(datatrain_rlm, direction = "backward",trace=T)
summary(datatrain_backward)
summary(datatrain_rlm)
#DATATRAIN RLM BACK
summary(datatrain_backward)
#DATATRAIN RLM
summary(datatrain_rlm)
plot(datatrain_rlm)
par(mfrow=c(2,2)) # VER LOS 4 GRAFICOS JUNTOS
par(mfrow=c(2,2)) # VER LOS 4 GRAFICOS JUNTOS
plot(datatrain_rlm)
plot(datatrain_backward)
datatrain_rlm_residuos = residuals(datatrain_rlm)
boxplot(datatrain_rlm_residuos, col = "blue",horizontal=TRUE,ylim = c(-2,2),main="Box-plot de residuos")
plot_datasetTrain_residuos <- plot_ly(y = ~datatrain_rlm_residuos, type = "box")
datatrain_rlm_residuos = residuals(datatrain_rlm)
boxplot(datatrain_rlm_residuos, col = "blue",horizontal=TRUE,ylim = c(-2,2),main="Box-plot de residuos")
plot_datasetTrain_residuos <- plot_ly(y = ~datatrain_rlm_residuos, type = "box")
plot_datasetTrain_residuos
datatrainback_rlm_residuos = residuals(datatrain_backward)
datatrain_backward = residuals(datatrainback_rlm_residuos)
datatrain_backward <- step(datatrain_rlm, direction = "backward",trace=T)
datatrainback_rlm_residuos = residuals(datatrain_backward)
datatrain_backward = residuals(datatrainback_rlm_residuos)
datatrain_rlm_residuos = residuals(datatrain_rlm)
datatrain_rlm <- lm(y ~ ., data = datafb_train)
datatrain_backward <- step(datatrain_rlm, direction = "backward",trace=T)
datatrain_backward <- step(data_fb, direction = "backward",trace=T)
datatrain_backward <- step(datatrain_rlm, direction = "backward",trace=T)
#DATATRAIN RLM BACK
summary(datatrain_backward)
datatrainback_rlm_residuos = residuals(datatrain_backward)
datatrainback_rlm_residuos = residuals(datatrain_backward)
datatrain_backward = residuals(datatrainback_rlm_residuos)
datatrain_backward = residuals(datatrainback_rlm_residuos)
boxplot(datatrain_backward, col = "blue",horizontal=TRUE,ylim = c(-2,2),main="Box-plot de residuos")
plot_datatrain_backward_residuos <- plot_ly(y = ~datatrainback_rlm_residuos, type = "box")
plot_datatrain_backward_residuos
plot_datatrain_backward_residuos <- plot_ly(y = ~datatrainback_rlm_residuos, type = "box")
plot_datatrain_backward_residuos
#Test de normalidad de Shapiro-Wilk (muestras chicas)
#Cuanto más cercano esté W a 1, más probable es que los datos se ajusten a una distribución normal.
#Si el p-valor es mayor que el nivel de significancia (ejemplo 0.05), se asume que los datos siguen una
#distribución normal.
modeltest <- datatrain_rlm
datatrain_rlm_residuos.test <- shapiro.test(datatrain_rlm_residuos)
print(datatrain_rlm_residuos.test)
dwtest(modeltest)
vif(datatrain_rlm)
dataTrain_corr
datafb_subset = subset(data_fb, x1=5000,x2=7390,x3=103,x4=101,x5=161,x6=3001,x7=2010,x8=254)
predict(datafb_subset)
predict(datatrain_rlm,datafb_subset)
#--------------------------------------------------------------------------------------------------------------
rm()
#--------------------------------------------------------------------------------------------------------------
rm(list = ls)
#--------------------------------------------------------------------------------------------------------------
rm(list = ls())
data_fb <- read_delim("DATOS/data.fb.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
data_fb <- read_delim("data.fb.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
setwd(C:/Users/Facundo/Desktop/UNO/Explotacion de Datos/Parcial - Recuperatorio/DATOS/data.fb.csv")
setwd("C:/Users/Facundo/Desktop/UNO/Explotacion de Datos/Parcial - Recuperatorio/DATOS/data.fb.csv")
setwd("C:\Users\Facundo\Desktop\UNO\Explotacion de Datos\Parcial - Recuperatorio\DATOS")
setwd("C:/Users/Facundo/Desktop/UNO/Explotacion de Datos/Parcial - Recuperatorio/DATOS")
data_fb <- read_delim("data.fb.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
#CARGAMOS LOS DATOS
rm(list = ls())
getwd()
data_fb <- read_delim("data.fb.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
str(data_fb)
sapply(data_fb, function(x) sum(is.na(x))) #VER SI HAY VALORES NULOS
attach(data_fb)
#CASTEAMOS LOS DATOS POR LAS DUDAS
data_fb$x1 <- suppressWarnings(as.numeric(data_fb$x1))
data_fb$x2 <- suppressWarnings(as.numeric(data_fb$x2))
data_fb$x3 <- suppressWarnings(as.numeric(data_fb$x3))
data_fb$x4 <- suppressWarnings(as.numeric(data_fb$x4))
data_fb$x5 <- suppressWarnings(as.numeric(data_fb$x5))
data_fb$x6 <- suppressWarnings(as.numeric(data_fb$x6))
data_fb$x7 <- suppressWarnings(as.numeric(data_fb$x7))
data_fb$x8 <- suppressWarnings(as.numeric(data_fb$x8))
data_fb$y <- suppressWarnings(as.numeric(data_fb$y))
attach(data_fb)
summary(data_fb)
data_fb <- data_fb[-77,]
nrow
nrow
nrow(data_fb)
summary(data_fb[,9])
data_fb$y_disc <- 1 # Agrego columna que contendra la cantidad de habitantes discretizada, por el momento el valor sera de 1.
data_fb <- data_fb %>%
mutate(y_disc  = case_when(.$y <= 71 ~ "bajo",
.$y <= 183 ~ "medio",
.$y <= 222 ~ "alto",
TRUE ~ "altisimo"
))
set.seed(2019)
data_fb_partition <- createDataPartition(data_fb$y, p=0.8, list=FALSE)
data_fb_partition2 <- createDataPartition(data_fb$y_disc, p=0.8, list=FALSE)
dtrain <- data_fb[data_fb_partition,]
dtest <- data_fb[-data_fb_partition,]
dtrain2 <- data_fb[data_fb_partition2,]
dtest2 <- data_fb[-data_fb_partition2,]
view(data_fb)
dtrain <- data_fb[data_fb_partition,[-9]]
dtrain <- data_fb[data_fb_partition[,-9],]
dtest <- data_fb[-data_fb_partition[,-9],]
view(dtest)
view(dtrain)
dtrain[-9]
dtrain[,-9]
view(dtrain)
dtrain <- dtrain[,-9]
view(dtrain)
dtest <- dtest[,-9]
dtrain <- dtrain[,-9]
dtest <- dtest[,-9]
view(dtrain)
view(dtest)
dtrain <- data_fb[data_fb_partition,]
dtest <- data_fb[-data_fb_partition,]
view(dtrain)
dtrain <- dtrain[,-9]
view(dtrain)
dtest <- dtest[,-9]
view(dtrain)
view(dtest)
tr_fit <- rpart(y_disc ~., data = dtrain, method="class") # Indicamos que deseamos un arbol de clasificacion, tambien podemos armar un arbol de regresion.
rpart.plot(tr_fit)
prediccion <- predict(tr_fit, newdata=dtest, type="class")
confusionMatrix(table(dtest$y_disc, prediccion,
dnn = c("Actual", "Predicho")))
setwd("C:/Users/Facundo/Desktop/UNO/Explotacion de Datos/Parcial - Recuperatorio/Recuperatorio/Datos")
getwd()
data_fb <- read_delim("data.fb.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
data_fb <- read_delim("data.fb.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
getwd()
data_fb <- read_delim("data.fb.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE)
